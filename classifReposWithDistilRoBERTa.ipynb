{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e41cc7",
   "metadata": {},
   "source": [
    "# NOTEBOOK 2 (Version optimisée faible RAM) : Fine-tuning de DistilRoBERTa\n",
    "\n",
    "**Objectif :** Ce notebook entraîne un classifieur **léger** pour assigner des catégories aux dépôts GitHub, en utilisant des techniques d'optimisation pour fonctionner dans un environnement à **mémoire vive (RAM) limitée**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf3d2c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy torch transformers datasets scikit-learn sentence-transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b743c070",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Hugging Face\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# Métriques et Utilitaires\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# Fichiers d'entrée\n",
    "INPUT_CSV_FILE = \"github_data_with_readmes.csv\"\n",
    "CATEGORIES_FILE = \"github_categories_database.json\"\n",
    "\n",
    "# Modèles\n",
    "BASE_MODEL = 'distilroberta-base' # <--- MODÈLE PLUS LÉGER\n",
    "EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "# Paramètres\n",
    "OUTPUT_MODEL_DIR = \"./distilroberta_github_classifier\"\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Utilisation du device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac027cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Chargement des données des dépôts\n",
    "df = pd.read_csv(INPUT_CSV_FILE)\n",
    "df['description'] = df['description'].fillna('')\n",
    "df['readme_content'] = df['readme_content'].fillna('')\n",
    "df['full_text'] = df['description'] + ' ' + df['readme_content']\n",
    "df = df[df['full_text'].str.strip().str.len() > 50].reset_index(drop=True)\n",
    "\n",
    "# Chargement de la base de catégories\n",
    "with open(CATEGORIES_FILE, 'r', encoding='utf-8') as f:\n",
    "    categories_db = json.load(f)\n",
    "\n",
    "id2label = {cat['category_id']: cat['category_name'] for cat in categories_db}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "N_LABELS = len(categories_db)\n",
    "\n",
    "print(f\"{len(df)} dépôts et {N_LABELS} catégories chargés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714cee1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Création des étiquettes pour l'entraînement supervisé...\")\n",
    "\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL, device=device)\n",
    "repo_embeddings = embedding_model.encode(\n",
    "    df['full_text'].tolist(), \n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "category_embeddings = np.array([cat['embedding_prototype'] for cat in categories_db])\n",
    "\n",
    "print(\"Assignation de la catégorie la plus proche à chaque dépôt...\")\n",
    "similarity_matrix = cosine_similarity(repo_embeddings, category_embeddings)\n",
    "df['label'] = np.argmax(similarity_matrix, axis=1)\n",
    "\n",
    "# --- Nettoyage Mémoire ---\n",
    "# On supprime les gros objets dont on n'a plus besoin avant l'entraînement\n",
    "del embedding_model, repo_embeddings, category_embeddings, similarity_matrix\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if device == 'cuda' else None\n",
    "print(\"Objets intermédiaires nettoyés de la mémoire.\")\n",
    "\n",
    "df.rename(columns={'full_text': 'text'}, inplace=True)\n",
    "df = df[['text', 'label']] # On ne garde que les colonnes utiles\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314a45d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Conversion en objet Dataset de Hugging Face\n",
    "full_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Division en jeux d'entraînement et de test\n",
    "hf_datasets = full_dataset.train_test_split(test_size=TEST_SIZE, stratify_by_column=\"label\")\n",
    "\n",
    "print(hf_datasets)\n",
    "\n",
    "# Tokenisation\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # On utilise une troncature dynamique pour économiser de la mémoire\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = hf_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ded10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Chargement du modèle pré-entraîné\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL, \n",
    "    num_labels=N_LABELS,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5b773",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_MODEL_DIR,\n",
    "    \n",
    "    # --- Optimisations Mémoire ---\n",
    "    per_device_train_batch_size=4,        # 1. Très petite taille de lot\n",
    "    gradient_accumulation_steps=8,        # 2. Accumuler les gradients pour simuler un lot de 4*8=32\n",
    "    optim=\"adamw_8bit\",                   # 3. Utiliser un optimiseur qui consomme 4x moins de mémoire\n",
    "    gradient_checkpointing=True,          # 4. Échange un peu de temps de calcul contre beaucoup de mémoire\n",
    "    fp16=True if device == 'cuda' else False, # 5. Utiliser des nombres à virgule flottante 16-bit (nécessite un GPU)\n",
    "\n",
    "    # --- Paramètres classiques ---\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Lancement du fine-tuning optimisé...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62abb3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- ÉVALUATION FINALE ---\n",
    "print(\"\\nÉvaluation du modèle final sur le jeu de test...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\n--- RÉSULTATS DE L'ÉVALUATION ---\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "trainer.save_model(OUTPUT_MODEL_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_MODEL_DIR)\n",
    "print(f\"\\n✅ Modèle fine-tuné et tokenizer sauvegardés dans '{OUTPUT_MODEL_DIR}'\")\n",
    "\n",
    "# --- TEST SUR UN NOUVEL EXEMPLE ---\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=OUTPUT_MODEL_DIR)\n",
    "new_repo_description = \"A lightweight CSS framework for minimalist and modern web design.\"\n",
    "prediction = classifier(new_repo_description)\n",
    "\n",
    "print(\"\\n--- TEST SUR UN NOUVEL EXEMPLE ---\")\n",
    "print(f\"Description: '{new_repo_description}'\")\n",
    "print(f\"Catégorie prédite : {prediction[0]['label']} (Score: {prediction[0]['score']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
